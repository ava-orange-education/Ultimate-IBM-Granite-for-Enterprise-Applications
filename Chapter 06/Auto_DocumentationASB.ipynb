{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6rko_ANX0EC"
   },
   "source": [
    "# Auto-generating Documentation: A Long Document Summarization Approach\n",
    "\n",
    "This notebook demonstrates an innovative application of long document summarization techniques to automatically generate documentation for Python code. By treating a codebase as a \"long document,\" we leverage AI-powered language models to comprehend, distill, and explain complex code structures.\n",
    "\n",
    "Key concepts:\n",
    "1. Document preprocessing: We fetch and format code from a GitHub repository, similar to how one might prepare a long text document for summarization.\n",
    "2. Chunking and tokenization: We analyze the token count of our code \"document\" to ensure it fits within the model's context window, a crucial step in long document processing.\n",
    "3. Prompt engineering: We craft a specialized prompt that guides the AI to focus on key aspects of the code, much like how summarization prompts direct models to capture essential information.\n",
    "4. AI-powered analysis: Using the Replicate API, we access a large language model capable of understanding code semantics and generating human-readable explanations.\n",
    "5. Structured output: We instruct the model to produce documentation in a consistent format, analogous to generating structured summaries from lengthy texts.\n",
    "\n",
    "This approach demonstrates how techniques traditionally used for summarizing long articles, reports, or books can be adapted for technical documentation tasks. It showcases the versatility of large language models in processing and synthesizing complex information, whether it's natural language or programming code.\n",
    "\n",
    "By the end of this notebook, you'll see how principles of long document summarization can be applied to streamline and enhance the software documentation process, potentially saving developers significant time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ASB commented the next non-working line out\n",
    "#!python -upgrade\n",
    "!sudo dnf upgrade python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwS1CzAbaFzq"
   },
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Before we begin, we need to install the required Python packages. We'll be using:\n",
    "\n",
    "- `replicate`: To interact with the Replicate API for accessing AI models\n",
    "- `transformers`: For tokenization and working with language models\n",
    "\n",
    "These packages will be installed using pip, Python's package installer. If you're running this notebook in a fresh environment, make sure you have pip installed and updated (if you are in Colab, this is done for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2zUHQD71qgqf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/ibm-granite-community/utils.git\n",
      "  Cloning https://github.com/ibm-granite-community/utils.git to /tmp/pip-req-build-2323f5m0\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils.git /tmp/pip-req-build-2323f5m0\n",
      "  Resolved https://github.com/ibm-granite-community/utils.git to commit 5d67648927240b208a164d2466f0dc77200450e5\n",
      "  Installing build dependencies ... \u001b[?done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: replicate in /home/alan/.local/lib/python3.11/site-packages (1.0.4)\n",
      "Requirement already satisfied: transformers in /home/alan/.local/lib/python3.11/site-packages (4.48.1)\n",
      "Requirement already satisfied: python-dotenv in /home/alan/.local/lib/python3.11/site-packages (from ibm-granite-community-utils==0.1.dev49) (1.0.1)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /home/alan/.local/lib/python3.11/site-packages (from replicate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /home/alan/.local/lib/python3.11/site-packages (from replicate) (24.2)\n",
      "Requirement already satisfied: pydantic>1.10.7 in /home/alan/.local/lib/python3.11/site-packages (from replicate) (2.10.6)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/alan/.local/lib/python3.11/site-packages (from replicate) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/alan/.local/lib/python3.11/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/alan/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alan/.local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: anyio in /home/alan/.local/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/alan/.local/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/alan/.local/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/alan/.local/lib/python3.11/site-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/alan/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/alan/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/alan/.local/lib/python3.11/site-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/alan/.local/lib/python3.11/site-packages (from pydantic>1.10.7->replicate) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alan/.local/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alan/.local/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/alan/.local/lib/python3.11/site-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/ibm-granite-community/utils.git replicate transformers\n",
    "#ASB Updated to use the latest version of Python installer\n",
    "!pip3.11 install git+https://github.com/ibm-granite-community/utils.git replicate transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydrVWz7EYHh9"
   },
   "source": [
    "## Set Replicate Token\n",
    "\n",
    "To use the Replicate API, we need to authenticate our requests. This is done using an API token.\n",
    "\n",
    "For security reasons, it's best to store this token as an environment variable rather than hardcoding it into our script. If we are using Google Colab, the `get_env_var` function will use the `userdata` feature to retrieve the token\n",
    "and set it in the environment variable.\n",
    "\n",
    "Remember to never share your API tokens publicly or commit them to version control systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "TSkiGBY4qo32",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r8_3XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "get_env_var(\"REPLICATE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d0sWaZ7YLHN"
   },
   "source": [
    "## Define a function for downloading a repository\n",
    "\n",
    "We'll create a function to fetch code from a GitHub repository. This allows us to easily obtain the code we want to document.\n",
    "\n",
    "Key points about this function:\n",
    "- It uses the GitHub API to retrieve repository contents\n",
    "- It can handle both files and directories recursively\n",
    "- The function formats the code with appropriate language tags for better display\n",
    "- An optional GitHub token can be provided for increased API rate limits and access to private repositories\n",
    "\n",
    "Note on GitHub tokens:\n",
    "A GitHub token is not required for public repositories, but it can be beneficial. With a token, you can:\n",
    "1. Access private repositories\n",
    "2. Have a higher rate limit for API requests\n",
    "3. Fetch more detailed information about the repository\n",
    "\n",
    "To create a GitHub token, go to your GitHub account settings, select \"Developer settings\", then \"Personal access tokens\".  Find more information [here](https://docs.github.com/en/rest/authentication/authenticating-to-the-rest-api?apiVersion=2022-11-28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3JFi40LArpIa"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_github_repo_contents(repo, directory_path, github_token = None):\n",
    "\n",
    "    api_url = f\"https://api.github.com/repos/{repo}/contents/{directory_path}\"\n",
    "    if github_token is not None:\n",
    "      headers = {'Authorization': f'token {github_token}'}\n",
    "      response = requests.get(api_url, headers = headers)\n",
    "    else:\n",
    "      response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    contents = response.json()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for item in contents:\n",
    "        if item['type'] == 'file':\n",
    "            file_response = requests.get(item['download_url'])\n",
    "            file_response.raise_for_status()\n",
    "            file_content = file_response.text\n",
    "            language = item['name'].split('.')[-1]\n",
    "            if language == 'py':\n",
    "                language = 'python'\n",
    "            elif language == 'js':\n",
    "                language = 'javascript'\n",
    "            result.append(f\"{item['path']}\\n```{language}\\n{file_content}\\n```\")\n",
    "        elif item['type'] == 'dir':\n",
    "            # Recursively go through subdirectories\n",
    "            subdirectory_contents = get_github_repo_contents(repo, item['path'], github_token)\n",
    "            result.append(subdirectory_contents)\n",
    "        sleep(0.1)\n",
    "\n",
    "    return \"\\n\\n\".join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-06VQn1YmtU"
   },
   "source": [
    "## Get code from `ibm-granite-community/utils`\n",
    "\n",
    "In this example, we're focusing on the `ibm-granite-community/utils` repository, specifically the `src` directory. This directory contains various utility functions that we want to document.\n",
    "\n",
    "By specifying this directory, we ensure that we're only fetching the relevant code and not unnecessary files or directories. This helps to keep our input focused and reduces the likelihood of exceeding token limits in our AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k2wS6rGJsu-T"
   },
   "outputs": [],
   "source": [
    "prompt = get_github_repo_contents(\"ibm-granite-community/utils\", \"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYuQmgRJY0n5"
   },
   "source": [
    "## Count the tokens\n",
    "\n",
    "Before sending our code to the AI model, it's crucial to understand how much of the model's capacity we're using. Language models typically have a limit on the number of tokens they can process in a single request.\n",
    "\n",
    "Key points:\n",
    "- We're using the `granite-8B-Code-instruct-128k` model, which has a context window of 128,000 tokens\n",
    "- The context window includes both the input (our code) and the output (the generated documentation)\n",
    "- Tokenization can vary between models, so we use the specific tokenizer for our chosen model\n",
    "- If our input is too large, we may need to split it into smaller chunks or summarize it\n",
    "\n",
    "Understanding token count helps us optimize our prompts and ensure we're using the model efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7JqmvTqbWPgl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your git repo load has 844 tokens\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"ibm-granite/granite-8B-Code-instruct-128k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "print(f\"Your git repo load has {len(tokenizer.tokenize(prompt))} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygNmITWQZAZ8"
   },
   "source": [
    "### Create our prompt and call the model in Replicate\n",
    "\n",
    "This is where we construct our final prompt and send it to the AI model for processing.\n",
    "\n",
    "Our approach involves:\n",
    "1. Combining the code we fetched with specific instructions for documentation\n",
    "2. Using a template to guide the model's output format\n",
    "3. Calling the Replicate API with our constructed prompt and additional parameters\n",
    "\n",
    "Key considerations:\n",
    "- The prompt includes both the code and instructions for how to document it\n",
    "- We use a response template to ensure consistent formatting across functions\n",
    "- Parameters like `max_tokens`, `temperature`, and `system_prompt` can be adjusted to fine-tune the model's behavior\n",
    "- The output is streamed, allowing for real-time display of the generated documentation\n",
    "\n",
    "This step is where the magic happens - transforming our code into human-readable documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yu4HeuqWqvOj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## `is_colab()`\n",
      "\n",
      "* `_return_`: (bool) True if the code is running in Google Colab, False otherwise.\n",
      "\n",
      "This function checks if the code is running in Google Colab by using the `importlib.util.find_spec` function to check if the `google.colab` module is installed. If it is, the function returns `True`, otherwise it returns `False`.\n",
      "\n",
      "## `get_env_var(var_name, default_value=None)`\n",
      "\n",
      "* `_param1_`: (str) The name of the environment variable to retrieve.\n",
      "* `_param2_`: (str | None) An optional default value to use if the environment variable is not set.\n",
      "* `_return_`: (str) The value of the environment variable.\n",
      "\n",
      "This function retrieves the value of an environment variable. If the environment variable is not set, the function searches for the variable in Colab secrets and then in a `.env` file. If the variable is not found in either location, the function prompts the user for a value. If a value is found, it is stored in the `os.environ` dictionary for future use.\n",
      "\n",
      "## `set_env_var(var_name, default_value)`\n",
      "\n",
      "* `_param1_`: (str) The name of the environment variable to set.\n",
      "* `_param2_`: (str | None) The value to set the environment variable to. If the value is not provided, the function will use the default value stored in the `os.environ` dictionary.\n",
      "* `_return_`: (None) This function does not return a value. It only sets the environment variable.\n",
      "\n",
      "This function sets the value of an environment variable. If the value is not provided, the function will use the default value stored in the `os.environ` dictionary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import replicate\n",
    "\n",
    "full_prompt = prompt + \"\"\"\n",
    "\n",
    "Provide detailed developer documentation for each function provided above.\n",
    "\n",
    "Response Template:\n",
    "## `function_name`\n",
    "\n",
    "* _param1_: (type) description\"\n",
    "\n",
    "Synopsis of the function\n",
    "\n",
    "_**returns**_:\n",
    "\"\"\"\n",
    "\n",
    "output = replicate.run(\n",
    "    \"ibm-granite/granite-8b-code-instruct-128k\",\n",
    "    input={\n",
    "\n",
    "        \"prompt\": full_prompt,\n",
    "        \"max_tokens\": 10000,\n",
    "        \"min_tokens\": 0,\n",
    "        \"temperature\": 0.75,\n",
    "        \"system_prompt\": \"You are a helpful assistant.\",\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"\".join(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
